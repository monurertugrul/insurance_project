{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b14b9b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523f172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_APPLICATION_CREDENTIALS = /Users/mustafaonurertugrul/Documents/Projects/insurance_project/vertex_key.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    \"/Users/mustafaonurertugrul/Documents/Projects/insurance_project/vertex_key.json\"\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"GOOGLE_APPLICATION_CREDENTIALS =\", os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ec8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71.1\n",
      "1.71.1\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "print(vertexai.__version__)\n",
    "print(aiplatform.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd240d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = (\n",
    "    \"/Users/mustafaonurertugrul/Documents/Projects/insurance_project/vertex_key.json\"\n",
    ")\n",
    "\n",
    "os.environ[\"VERTEX_PROJECT_ID\"] = \"insurance-vertex\"\n",
    "os.environ[\"VERTEX_LOCATION\"] = \"us-central1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07800641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: vertex-runner@insurance-vertex.iam.gserviceaccount.com\n",
      "Project: insurance-vertex\n"
     ]
    }
   ],
   "source": [
    "from google.auth import default\n",
    "creds, project = default()\n",
    "print(\"Authenticated as:\", creds.service_account_email)\n",
    "print(\"Project:\", project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec9c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ FAILED: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Use 'http_options' to ensure no proxy or versioning interference\n",
    "client = genai.Client(\n",
    "    api_key=\"AIza...\", \n",
    "    http_options={'api_version': 'v1beta'} # Sometimes 'v1' is stricter\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        contents=\"Hello\"\n",
    "    )\n",
    "    print(\"✅ SUCCESS!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ FAILED: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162bb43c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Publisher Model `projects/insurance-vertex/locations/us-central1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_InactiveRpcError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:75\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/grpc/_channel.py:1159\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1156\u001b[39m state, call = \u001b[38;5;28mself\u001b[39m._blocking(\n\u001b[32m   1157\u001b[39m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[32m   1158\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/grpc/_channel.py:990\u001b[39m, in \u001b[36m_end_unary_response_blocking\u001b[39m\u001b[34m(state, call, with_call, deadline)\u001b[39m\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m state.response\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[31m_InactiveRpcError\u001b[39m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Publisher Model `projects/insurance-vertex/locations/us-central1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2a00:1450:400c:c0c::5f%5D:443 {grpc_message:\"Publisher Model `projects/insurance-vertex/locations/us-central1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\", grpc_status:5}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     36\u001b[39m features = {\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m40\u001b[39m,\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msex\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmale\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msmoker\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m }\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 6. Predict\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m result = \u001b[43mensemble\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/agents/ensemble_agent_light.py:55\u001b[39m, in \u001b[36mEnsemblePredictor.predict\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m     52\u001b[39m frontier_explanation = frontier_result.get(\u001b[33m\"\u001b[39m\u001b[33mexplanation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 3. GeminiFrontierAgent prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m gemini_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgemini_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m gemini_price = gemini_result.get(\u001b[33m\"\u001b[39m\u001b[33mpredicted_charges_usd\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m gemini_explanation = gemini_result.get(\u001b[33m\"\u001b[39m\u001b[33mexplanation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/agents/gemini_frontier_agent.py:72\u001b[39m, in \u001b[36mGeminiFrontierAgent.price\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m     69\u001b[39m similar_cases = \u001b[38;5;28mself\u001b[39m.rag.retrieve(features, k=\u001b[32m3\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rag \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m     70\u001b[39m prompt = \u001b[38;5;28mself\u001b[39m._build_prompt(features, similar_cases)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m text = response.text\n\u001b[32m     75\u001b[39m match = re.search(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m{\u001b[39m\u001b[33m.*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m}\u001b[39m\u001b[33m\"\u001b[39m, text, re.DOTALL)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:654\u001b[39m, in \u001b[36m_GenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[39m\n\u001b[32m    645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content_streaming(\n\u001b[32m    646\u001b[39m         contents=contents,\n\u001b[32m    647\u001b[39m         generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    651\u001b[39m         labels=labels,\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:779\u001b[39m, in \u001b[36m_GenerativeModel._generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[39m\n\u001b[32m    752\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[32m    753\u001b[39m \n\u001b[32m    754\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    769\u001b[39m \u001b[33;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    771\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m    772\u001b[39m     contents=contents,\n\u001b[32m    773\u001b[39m     generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    777\u001b[39m     labels=labels,\n\u001b[32m    778\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m gapic_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prediction_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_response(gapic_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2159\u001b[39m, in \u001b[36mPredictionServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m   2158\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2159\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2164\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2166\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m   2167\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/insurance_project/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 Publisher Model `projects/insurance-vertex/locations/us-central1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions"
     ]
    }
   ],
   "source": [
    "from rag.retriever_xgboost import InsuranceRAG_XGB\n",
    "from agents.frontier_agent import FrontierAgent\n",
    "from agents.gemini_frontier_agent import GeminiFrontierAgent\n",
    "from agents.ensemble_agent_light import EnsemblePredictor\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 1. RAG retriever\n",
    "rag = InsuranceRAG_XGB(\n",
    "    model_path=\"./rag/xgb_model.json\",\n",
    "    db_path=\"./chroma_db\",\n",
    "    collection_name=\"insurance_cases_xgb\",\n",
    ")\n",
    "\n",
    "# 2. FrontierAgent (OpenAI)\n",
    "frontier = FrontierAgent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    rag=rag,\n",
    ")\n",
    "\n",
    "# 3. GeminiFrontierAgent (Gemini)\n",
    "gemini = GeminiFrontierAgent(\n",
    "    model=\"gemini-pro\",\n",
    "    rag=rag,\n",
    ")\n",
    "\n",
    "# 4. EnsemblePredictor (XGBoost + Frontier + Gemini)\n",
    "ensemble = EnsemblePredictor(\n",
    "    xgb_model_path=\"./rag/xgb_model.json\",\n",
    "    frontier_agent=frontier,\n",
    "    gemini_agent=gemini,   # <-- REQUIRED NOW\n",
    ")\n",
    "\n",
    "# 5. Sample input\n",
    "features = {\n",
    "    \"age\": 40,\n",
    "    \"sex\": \"male\",\n",
    "    \"bmi\": 28.5,\n",
    "    \"children\": 2,\n",
    "    \"smoker\": \"no\",\n",
    "}\n",
    "\n",
    "# 6. Predict\n",
    "result = ensemble.predict(features)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ff27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
